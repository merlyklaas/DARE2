---
title: "Holden (2016) Data Replication & Extension"
author: "Anwesha Guha, Merly Klaas, Thuy Nguyen"
date: "1/27/2022"
output:
  html_document:
    toc: yes
    toc_float: yes
    highlight: espresso
    code_folding: hide
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
	echo = TRUE,
	message = FALSE,
	warning = FALSE)

library(pacman)
# These are the packages you will need for the analyses 
p_load(here, rio, tidyverse, DT, ggplot2, xaringan, knitr, kableExtra, modelsummary, stargazer, xaringanthemer, gganimate, ggthemes, fixest, haven, gtsummary)

dat <- import(here("data", "EDLD_650_CA_schools_es.dta"))
``` 

*In this project, you will replicate and extend analysis from Holden (2016). In the dataset EDLD_650_CA_school es.dta, you will find the variables listed in Table 1. The dataset includes school years 2003-2009. Without binning the forcing variable, your figures will look slightly different than those in Holden. This is fine and will not affect the substantive conclusions. If you would like to set yourself a data management challenge, attempt to mirror the figures exactly! Pay careful attention throughout to which years you should be using in your analyses.*

### A. Assumption tests (4 points)

*For the following tasks, give your best attempt at completing the analysis and write-up. If you are unable to conduct the programming or analysis, describe what you are attempting to do and what your results would mean.*

**A1.** Create a figure that describes whether the forcing variable predicts the question variable of interest. Specifically, did a school with an Academic Performance Index (API) of 643 or lower in 2003 receive additional instructional material funding in 2005? Present the figure and associated write-up as you would report these in an academic paper in 2-3 sentences.

In the paper, the following are the variables relevant to this question.

* `api_rank` = shows school's academic performance in 2003 (x)

* `receive_williams` = shows receipt of award in 2005 (observed y)

* `ind` = shows intended receipt of award (intended y)

Create figure with variables below.
```{r}
#receipt of treatment (receipt Williams) against forcing variable

treat <- ggplot() +
  #actual recipient
  geom_jitter(data=dat, aes(x=api_rank, y=receive_williams), color="#3b3b9a", alpha=0.4, shape=16) + 
  #intended recipient
  geom_line(data=dat, aes(x=api_rank, y=ind), color="#e64173", linetype="dashed", size = 1) +
  theme_minimal() +
  scale_x_continuous("API Score") +
  scale_y_continuous("Award Received")

treat
```

The graph shows that the forcing variable `api_rank`, which is the academic performance rank in 2003 which intends to determine eligibility for Williams, does indeed predict (some) change in the probability of treatment, which is the receipt of the Williams award in 2005. The API score of 643 largely separates recipient and non-recipient groups.

**A2.** Is there evidence of schools manipulating their placement around the discontinuity? Present at least two figures demonstrating (a) whether there is evidence that schools attempted to receive an API score that would have made them eligible to receive additional funding; and (b) whether there is evidence that schools that did and did not receive Williams funding were different in observable ways. These figures should present characteristics of schools that are exogenous to the receipt of Williams funding (think about what would be exogenous in this case). Present the figures and associated write-up as you would report these in an academic paper in 1-2 paragraphs. 

```{r}
# Examine bunching
# Zoom in on just the first cut (above/below 643 with 19.099 bandwidth of the cutoff)

dat<- dat %>%
  filter(api_rank >= (643-19.099)& api_rank <= (643+19.099)) # can choose to re-run treat graph above with this data for a cleaner look

bunch <- dat %>%
  ggplot(aes(api_rank)) +
  geom_bar(fill = "cyan3", alpha=.6) +
  geom_vline(xintercept = 643, color = "red") + 
  labs(x = "API in 2003 relative to cutoff") +
  theme_minimal()
bunch
```

There is no evidence of bunching around the 643 cutoff. This makes sense according to Holden's design: 2003 is unambiguously pre-Williams settlement. While 2004 and onwards may expect lower-income schools to manipulate API score to increases textbook funding for their students, that opportunity was not known at this time.


**Smoothness of Average in test score Before Disbursal of Textbook funding in Elementary Schools**

```{r}
a03 <-  dat %>% 
  filter(year == "2003") %>% 
  group_by(api_rank) %>% 
     summarise(across(c("average_score", "ind"), mean)) %>% 
  ggplot() +
   geom_point(aes(x=api_rank, y=average_score), color = "turquoise3") + 
  scale_x_binned(n.breaks = 20) +
  scale_x_discrete() +
  geom_vline(xintercept = 643) +
   labs(x ="API in 2003 relative to cutoff",
        y = "Average Std. Test Score by school",
        title = " Average Score Pre-treatment in 2003")+
  theme_tufte() 
a03


a04 <-  dat %>% 
  filter(year == "2004") %>% 
  group_by(api_rank) %>% 
     summarise(across(c("average_score", "ind"), mean)) %>% 
  ggplot() +
   geom_point(aes(x=api_rank, y=average_score), color = "gray") + 
  scale_x_binned(n.breaks = 20) +
  scale_x_discrete() +
  geom_vline(xintercept = 643) +
   labs(x ="API in 2003 relative to cutoff",
        y = "Average Std. Test Score by school",
        title = " Average Score Pre-treatment in 2004")+
  theme_bw()
a04

```
**Smoothness of Student Characteristics Before Disbursal of Textbook Funding in Elementary Schools**

```{r}
en04 <-  dat %>% 
  filter(year == "2003") %>% 
   group_by(api_rank) %>% 
     summarise(across(c("total", "ind"), mean)) %>% 
  ggplot() +
   geom_point(aes(x=api_rank, y= total), color = "grey") + 
  scale_x_binned(n.breaks = 20) +
  scale_x_discrete() +
  geom_vline(xintercept = 643) +
   labs(x ="API in 2003 relative to cutoff",
        y = "Enrollment in 2003",
        title = " School Enrollment Pre-treatment in 2003") +
  theme_bw()
en04

frlp <- dat %>% 
  filter(year == "2003") %>% 
  ggplot() +
  geom_boxplot(aes(x=as.factor(api_rank), y=percentfrl), fill="tomato3", alpha=0.4) +
  geom_vline(xintercept = 643, color = "red") +
   labs(x ="API in 2003 relative to cutoff",
        y = "Pct eligible for FRPL in 2003",
        title = "Percent Free and Reduced Lunch") +
   theme(axis.text.x = element_text(angle = 45, vjust = 0.5, hjust=1)) 
frlp

```

**Smoothness of Staff Characteristics Before Disbursal of Textbook funding in Elementary Schools**


```{r}
staff <-  dat %>% 
  filter(year == "2004") %>% 
  group_by(norm) %>% 
     summarise(across(c("yrs_teach", "ind"), mean)) %>% 
  ggplot() +
   geom_point(aes(x=norm, y= yrs_teach), color = "gray") + 
  geom_vline(xintercept = 0) +
   labs(x ="API in 2003 relative to cutoff",
        y = "Average Year of Teacher Teaching Experience",
        title = " Teacher Experience Pre-treatment in 2004") +
  theme_bw()
staff

dist <-  dat %>% 
  filter(year == "2004") %>% 
  group_by(norm) %>% 
     summarise(across(c("yrs_dist", "ind"), mean)) %>% 
  ggplot() +
   geom_point(aes(x=norm, y= yrs_dist), color = "gray") + 
  geom_vline(xintercept = 0) +
   labs(x ="API in 2003 relative to cutoff",
        y = "Years in District",
        title = " Teacher Experience in District level Pre-treatment in 2004") +
  theme_bw()
staff

```

The falsifications tests for individual school characteristics were conducted through the smoothness visual inspections to the numbers of school characteristics before disbursal of textbook funding that are exogenous to the receipt of Williams funding including: a. Average Test Score, b. Student Characteristics, and  c. Staff Characteristics. 

Each figure shows each school characteristics distributions pre-treatment are smooth through the cutoff prior to treatment. This suggests that schools right below and above cutoff are equal in expectation prior to treatment.


**A3** Optional Extension Construct a table of summary statistics. What are the sample characteristics of the subset of elementary schools in our dataset? What is different about our data from the full data used in Holden (2016) and how might that affect the interpretation of results? Present the table and associated write-up as you would report these in an academic paper in 1-2 paragraphs.

```{r}
sum <- import(here("data", "EDLD_650_CA_schools_es.dta")) 
sum %>% 
  select(
    "Math Score" = mathscore,
    "Reading Score"= readingscore, 
    "API score in 2003" = api_rank,
   " Total Enrolment "= total, 
    "Percent Hispanic" = pct_hi,
    "Percent White" = pct_wh,
   "Percent FRPL eligible" = percentfrl) %>%
tbl_summary(statistic = list(all_continuous() ~ "{mean}")) %>%
  modify_caption("**Summary Statistics for Elementary School Sample**") 


dat %>%
  select(
    "Math Score" = mathscore,
    "Reading Score" = readingscore, 
    "API score in 2003" = api_rank,
   "Total Enrolment"= total, 
    "Percent Hispanic" = pct_hi,
    "Percent White" = pct_wh,
   "Percent FRPL eligible" = percentfrl) %>%
tbl_summary(statistic = list(all_continuous() ~ "{mean}"),
            digits = all_continuous() ~ 2) %>% 
  modify_caption("**Summary Statistics of 19.099 API Bandwith around eligibility cutoff**") 

```

Summary statistics tables presented here are only for Elementary school-year observation (Table 1) and those within 19.099 API Bandwidth (Table 2), respectively n= 16,462 and n = 3,725, while Holden (2016) used full sample including Middle and High School-year observation (n=54,803). Thus, the interpretation of the summary stats reflects only Elementary School characteristics. 


### B. Replication and Extension (6 points)

*For the following tasks, give your best attempt at completing the analysis and write-up. If you are unable to conduct the programming or analysis, describe what you are attempting to do and what your results would mean. For these tasks, think about what bandwidth is the correct one to present for your main results.*

**B1.** Did the receipt of additional funds for instructional materials improve test score outcomes for elementary students in California? Construct a figure that presents graphical evidence in support of your answer to this question. Pay close attention to the bandwidth of analysis Holden selects. Either use the same bandwidth or justify a different selection. Write up your description of this figure in one (1) paragraph as you would for an academic paper. If you have not completed the previously mentioned data management tasks to bin the forcing variable, explain how and why your figure looks different from the original figure in 2-3 sentences.


```{r}
dat$ind <- as.factor(dat$ind)

fx <- dat %>% 
  ggplot() +
  geom_point(aes(x=api_rank, y=average_score, color = ind), alpha=0.8, shape=16) +
  geom_vline(xintercept = 643, color = "#314f4f", size = 1.5, alpha = 0.5) +
  theme_pander(base_size = 18) +
  xlab("API score") + 
  ylab("Average score") 

fx
```

```{r}
bin <- dat %>% group_by(api_rank) %>% 
     summarise(across(c("average_score", "ind"), mean))

bin <- bin %>% mutate(low = ifelse(api_rank <= 643,TRUE,FALSE))

fx_binned <- bin %>% 
  ggplot(aes(x=api_rank, y=average_score, color = low)) +
  geom_point(alpha=0.8, shape=16) +
  geom_smooth(method = "lm", se=FALSE) +
  geom_vline(xintercept = 643, color = "#314f4f", size = 1, alpha = 0.5) +
  theme_pander(base_size = 18) +
  xlab("API score") + 
  ylab("Average score") 

fx_binned
```

We wanted to see the test scores broken down by subject, so the code for that exploration is also below.
```{r}
bin_reading <- dat %>% group_by(api_rank) %>% 
     summarise(across(c("readingscore", "ind"), mean))

bin_reading <- bin_reading %>% mutate(low = ifelse(api_rank <= 643,TRUE,FALSE))

reading_binned <- bin_reading %>% 
  ggplot(aes(x=api_rank, y=readingscore, color = low)) +
  geom_point(alpha=0.8, shape=16) +
  geom_smooth(method = "lm", se=FALSE)+
  geom_vline(xintercept = 643, color = "#314f4f", size = 1, alpha = 0.5) +
  theme_pander(base_size = 18) +
  xlab("API score") + 
  ylab("Reading score") 

reading_binned
```

```{r}
bin_math <- dat %>% group_by(api_rank) %>% 
     summarise(across(c("mathscore", "ind"), mean))

bin_math <- bin_math %>% mutate(low = ifelse(api_rank <= 643,TRUE,FALSE))

math_binned <- bin_math %>% 
  ggplot(aes(x=api_rank, y=mathscore, color = low)) +
  geom_point(alpha=0.8, shape=16) +
  geom_smooth(method = "lm", se=FALSE) +
  geom_vline(xintercept = 643, color = "#314f4f", size = 1, alpha = 0.5) +
  theme_pander(base_size = 18) +
  xlab("API score") + 
  ylab("Math score")

math_binned
```

To allow for non-linear (quadratic) forcing variable trends for average scores, we created the following plot, though the fit of this plot does not seem to improve with the added quadratic term.
```{r}
fx_binned2 <- bin %>% 
  ggplot(aes(x=api_rank, y=average_score, color = low)) +
  geom_point(alpha=0.8, shape=16) +
  geom_smooth(method = "lm", formula=y ~ poly(x,2), se=TRUE) +
  geom_vline(xintercept = 643, color = "#314f4f", size = 1, alpha = 0.5) +
  theme_pander(base_size = 18) +
  xlab("API score") + 
  ylab("Average score") 

fx_binned2
```



**B2.** In a regression framework, formally test whether the receipt of additional funds for instructional materials improved test score outcomes for elementary students in California. Present these results in a table and associated 1-2 paragraph write-up as you would in an academic paper.

```{r}
library(modelsummary)
linear_const <- lm(average_score ~ api_rank + I(api_rank<643), bin)
linear_diff <- lm(average_score ~ api_rank * I(api_rank<643), bin)
quadratic <- lm(average_score ~ poly(api_rank,2) + I(api_rank<643), bin)

modelsummary(list(linear_const, linear_diff, quadratic), 
             stars=T,
             coef_rename = c("(Intercept)" = "Intercept", "api_rank" = "Academic Performance", "I(api_rank < 643)TRUE" = "Intended Award",
                             "api_rank:I(api_rank < 643)TRUE" = "Score x Award", 
                             "poly(api_rank, 2)1" = "Intended Award", "poly(api_rank, 2)2" = "(Intended Award)^2"),
             gof_omit = "Adj|Pseudo|Log|Within|AIC|BIC|FE|Std|F"
            )
```

Following that the additional $96.90 per student for textbook funds significantly increased school-average STAR test scores by 0.15 standard deviations in the paper, Model 1 and Model 3 also suggest a positive relationship between receiving additional funding and increased test scores.

**B3.** Write a discussion paragraph in which you present the substantive conclusions (and limitations) of your results about the effects of added textbook funding for California elementary school students.
```{r}
-6.405+.009*644-8.927*0+.014*644*0 #did not receive funds
-6.405+.009*642-8.927*1+.014*644*1 #received funds
.609-.538
```

The predicted effect of receiving additional textbook funding when we allow the slopes to vary around the discontinuity is .071, slightly smaller than the constant linear or quadratic slopes. While the overall academic performance may be negative, there is less of a negative effect whne schools receive the award.
Similar to Holden, the estimated discontinuity in 2005 is being driven by change in the slope of points near the threshold. These results are relevant and generalizable to other schools on the cusp, not high-performing schools or schools with greater baseline textbook funding in the first place.

**B4.** Optional Extension Present a series of robustness checks to the main results you have found. Consider varying year, functional form and bandwidth of your estimates.

```{r}

```




 