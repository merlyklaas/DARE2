---
title: "Untitled"
author: "Anwesha Guha, Merly Klaas, Thuy Nguyen,"
date: "1/27/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
	echo = TRUE,
	message = FALSE,
	warning = FALSE)

library(pacman)
# These are the packages you will need for the analyses 
p_load(here, rio, tidyverse, DT, ggplot2, xaringan, knitr, kableExtra, modelsummary, stargazer, xaringanthemer, gganimate, ggthemes, fixest, haven)

dat <- import(here("data", "EDLD_650_CA_schools_es.dta"))


``` 

*In this project, you will replicate and extend analysis from Holden (2016). In the dataset EDLD 650 CA school es.dta, you will find the variables listed in Table 1. The dataset includes school years 2003-2009. Without binning the forcing variable, your figures will look slightly different than those in Holden. This is fine and will not affect the substantive conclusions. If you would like to set yourself a data management challenge, attempt to mirror the figures exactly! Pay careful attention throughout to which years you should be using in your analyses.*

### A. Assumption tests (4 points)

*For the following tasks, give your best attempt at completing the analysis and write-up. If you are unable to conduct the programming or analysis, describe what you are attempting to do and what your results would mean.*

**A1.** Create a figure that describes whether the forcing variable predicts the question variable of interest. Specifically, did a school with an Academic Performance Index (API) of 643 or lower in 2003 receive additional instructional material funding in 2005 ? Present the figure and associated write-up as you would report these in an academic paper in 2-3 sentences.

```{r}

#schools with API of 643 or lower in 2003:
data_a1 <- data %>% 
  filter(year == 2003 & norm <= 0) 

# y = receive of treatment = receive_williams; 
# x = forcing variable = api_rank (or norm)
#receipt of treatment (receipt Williams) against forcing variable (API score)

treat <- ggplot() +
  #actual recipient
  geom_jitter(data=data, aes(x=api_rank, y=receive_williams), color=grey_mid,alpha=0.4, shape=16) + 
  
  # filter year 2003 and API 643 or lower (norm <=0 )
  geom_jitter(data=data_a1, aes(x=api_rank, y=receive_williams), color="blue",alpha=0.4, shape=16)+
  
  #intended recipient
  geom_line(data=data, aes(x=api_rank, y=ind), color=red_pink, linetype="dashed", size = 1.5) +
  theme_pander(base_size = 18) + scale_x_continuous("API Score") +
  scale_y_discrete("Received Williams")

treat
```

**A2.** Is there evidence of schools manipulating their placement around the discontinuity? Present at least two figures demonstrating (a) whether there is evidence that schools attempted to receive an API score that would have made them eligible to receive additional funding; and (b) whether there is evidence that schools that did and did not receive Williams funding were different in observable ways. These figures should present characteristics of schools that are exogenous to the receipt of Williams funding (think about what would be exogenous in this case). Present the figures and associated write-up as you would report these in an academic paper in 1-2 paragraphs. 

```{r}
# Examine bunching
# Zoom in on just the first cut (above/below 643 with 19.099 bandwidth of the cutoff)

dat<- dat %>%
  filter(api_rank >= (643-19.099)& api_rank <= (643+19.099))

bunch <- dat %>%
  ggplot(aes(api_rank)) +
  geom_bar(fill = "cyan3") +
  geom_vline(xintercept = 643, color = "red") + 
  labs(x = "API in 2003 relative to cutoff", 
       )
bunch


#  Examine whether pre-treatment characteristics differ around the cutoff score discontinuity (binned scatterplot of covariates around discontinuity)


## Differences in FRLP status
sort <- ggplot() +
  geom_boxplot(data=dat, aes(x=as.factor(api_rank), y=percentfrl), fill="tomato3", alpha=0.4) +
  theme_pander(base_size = 20) +
  xlab("API in 2003 relative to cutoff") + scale_y_continuous("Percent of Low-Income students")+
  theme(axis.text.x = element_text(angle = 45, vjust = 0.5, hjust=1),
        axis.text=element_text(size=12),
        axis.title=element_text(size=14,face="bold")) +
  theme_tufte()
sort

dat <-dat %>% mutate(low = ifelse(api_rank <= 643,TRUE,FALSE))




```

**A3** Optional Extension Construct a table of summary statistics. What are the sample characteristics of the subset of elementary schools in our dataset? What is different about our data from the full data used in Holden (2016) and how might that affect the interpretation of results? Present the table and associated write-up as you would report these in an academic paper in 1-2 paragraphs.

### B. Replication and Extension (6 points)

*For the following tasks, give your best attempt at completing the analysis and write-up. If you are unable to conduct the programming or analysis, describe what you are attempting to do and what your results would mean. For these tasks, think about what bandwidth is the correct one to present for your main results.*

```{r}
library(here)
library(rio)
library(tidyverse)
library(ggthemes)

holden <- import(here("data", "EDLD_650_CA_schools_es.dta"))
```


**B1.** Did the receipt of additional funds for instructional materials improve test score outcomes for elementary students in California? Construct a figure that presents graphical evidence in support of your answer to this question. Pay close attention to the bandwidth of analysis Holden selects. Either use the same bandwidth or justify a different selection. Write up your description of this figure in one (1) paragraph as you would for an academic paper. If you have not completed the previously mentioned data management tasks to bin the forcing variable, explain how and why your figure looks different from the original figure in 2-3 sentences.

ind = if they received funds
average_score = predictor, measured in school-level standard deviations
Holden only uses 2006 values (p. 106)
```{r}
mod <- lm(average_score ~ ind, data=holden)
summary(mod)
```
```{r}
holden %>% 
  ggplot()+
  geom_jitter(aes(x=ind, y=average_score), color="grey50", alpha=0.4, shape=16) +
  geom_line(aes(x=ind, y = average_score), color="#e64173", linetype="dashed", size=1.5)
```

# Check if the forcing variable 

fx <- dat %>% 
  ggplot() +
  geom_point(data=dat, aes(x=api_rank, y=readingscore, color = low), alpha=0.8, shape=16) +
  geom_vline(xintercept = 643, color = slate, size = 1.5, alpha = 0.5) +
  theme_pander(base_size = 18) +
  xlab("API score") + ylab("Reading score") 

fx


bin <- dat %>% group_by(api_rank) %>% 
     summarise(across(c("readingscore", "low"), mean))

binned_plot <- ggplot() + 
  geom_point(data=bin, aes(x=api_rank, y=readingscore, colour=as.factor(low)), alpha=0.8, shape=16, size=3) +
  geom_vline(xintercept = 643, color = slate, size = 1.5, alpha = 0.5) + 
  theme_pander(base_size = 18) + xlab("API score relative to cutoff") + ylab("Reading score") + 
  scale_color_manual(values = c(purple, red_pink)) +
  theme(legend.position = "none")

binned_plot
```


**B2.** In a regression framework, formally test whether the receipt of additional funds for instructional materials improved test score outcomes for elementary students in California. Present these results in a table and associated 1-2 paragraph write-up as you would in an academic paper.

```{r}
library(modelsummary)
linear_const <- lm(average_score ~ api_rank + I(api_rank<643), holden)
linear_diff <- lm(average_score ~ api_rank * I(api_rank<643), holden)
quadratic <- lm(average_score ~ poly(api_rank,2) + I(api_rank<643), holden)

modelsummary(list(linear_const, linear_diff, quadratic), 
             stars=T,
             coef_rename = c("(Intercept)" = "Intercept", "api_rank" = "api_rank", "I(api_rank <643)TRUE" = "Intended small class",
                             "size:I(size > 40.5)TRUE" = "Size x Small", 
                             "poly(size, 2)1" = "Intended size", "poly(size, 2)2" = "(Intended size)^2"),
             gof_omit = "Adj|Pseudo|Log|Within|AIC|BIC|FE|Std|F"
            )
```

```{r, results='asis'}
library(modelsummary)
linear_const <- lm(average_score ~ norm + I(norm<0), holden)
linear_diff <- lm(average_score ~ norm * I(norm<0), holden)
quadratic <- lm(average_score ~ poly(norm,2) + I(norm<0), holden)

modelsummary(list(linear_const, linear_diff, quadratic), 
             stars=T,
             coef_rename = c("(Intercept)" = "Intercept", "norm" = "api_rank", "I(api_rank <643)TRUE" = "Intended small class",
                             "size:I(size > 40.5)TRUE" = "Size x Small", 
                             "poly(size, 2)1" = "Intended size", "poly(size, 2)2" = "(Intended size)^2"),
             gof_omit = "Adj|Pseudo|Log|Within|AIC|BIC|FE|Std|F"
            )
```

**B3.** Write a discussion paragraph in which you present the substantive conclusions (and limitations) of your results about the effects of added textbook funding for California elementary school students.
```{r}

```

**B4.** Optional Extension Present a series of robustness checks to the main results you have found. Consider varying year, functional form and bandwidth of your estimates.

```{r}

```




 